\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{gensymb}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{datetime}
\usepackage{amsmath, bm}
\usepackage{upgreek}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\newdateformat{monthyear}{\monthname[\THEMONTH], \THEYEAR}

\begin{document}

\pagenumbering{gobble}

\begin{center}

\HRule \\[0.4cm]
{ \huge \bfseries Lab 2: INS and Kalman Filter \\[0.4cm] 
\Large \bfseries TTK5: Kalman Filtering and Navigation \\[0.4cm] } 

\HRule \\[1.5cm]

\begin{center} \large
\emph{By:}\\
\textbf{Andreas Nordby Vibeto}\\
andvibeto@gmail.com \\
(andreanv@stud.ntnu.no)
\end{center}

\vfill

{\large \monthyear\today}

\end{center}
\newpage
\pagenumbering{arabic}

\section*{Task 1}
\begin{figure}[!ht]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.25\textwidth, keepaspectratio=true]{../src/task1.eps}}
    \caption{True acceleration and angular velocity.}
\end{figure}

\section*{Task 2}
In order to discretize the system, it must first be written as a state space model. The system

\begin{subequations}
\begin{equation}
	\dot{x} = v 
\end{equation}
\begin{equation}
	\dot{v} = a
\end{equation}
\begin{equation}
	\dot{\theta} = \omega
\end{equation}
\end{subequations}

can be written as

\begin{subequations}
\begin{equation}
	\dot{\bm{x}} = \bm{A}\bm{x} + \bm{B}\bm{u}
\end{equation}
\begin{equation}
	\begin{bmatrix}
		\dot{x} \\ \dot{v} \\ \dot{\theta}
	\end{bmatrix}
	=
	\begin{bmatrix}
		0 & 1 & 0 \\
		0 & 0 & 0 \\
		0 & 0 & 0
	\end{bmatrix}
	\begin{bmatrix}
		x \\ v \\ \theta
	\end{bmatrix}
	+
	\begin{bmatrix}
		0 & 0 \\
		1 & 0 \\
		0 & 1
	\end{bmatrix}
	\begin{bmatrix}
		a \\ \omega
	\end{bmatrix}
	.
\end{equation}
\end{subequations}

By using forward Euler to discretize the system, it can be written on the form

\begin{equation}
	\label{eq:euler}
	\bm{x}(t_{k+1}) = (\bm{I} + h\bm{A}(t_k))\bm{x}(t_k) + h\bm{B}(t_k)\bm{u}(t_k)
\end{equation}

where $h$ is the step size. The discretized system then becomes

\begin{equation}
	\bm{x}(t_{k+1}) =
	\begin{bmatrix}
		1 & h & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 1
	\end{bmatrix}
	\bm{x}(t_k) + 
	\begin{bmatrix}
		0 & 0 \\
		h & 0 \\
		0 & h
	\end{bmatrix}
	\bm{u}(t_k).
\end{equation}

Figure \ref{fig:disc_states} shows plots of the states in the discretized system.

\begin{figure}[!ht]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.25\textwidth, keepaspectratio=true]{../src/disc_states.eps}}
    \caption{States of the discretized system.}
    \label{fig:disc_states}
\end{figure}


\section*{Task 3}
When white noise is expressed in discrete time it is referred to as a white sequence \cite{heftet}, where the sequence consists of random variables that are uncorrelated \cite{wikiWhite}. The autocorrelation function for discrete white noise is:

\begin{equation}
	R_d(k) = A\delta(k) , \hspace{5pt} \delta(k) =
	\begin{cases}
		1 \hspace{10pt} k = 0 \\
		0 \hspace{10pt} k \neq 0
	\end{cases}.
\end{equation}

When using Matlab, white Gaussian noise can be generated by using \texttt{wgn()}, which will generate a sequence of uncorrelated random variables, which can be regarded as a white sequence.

The biases $b_1$ and $b_2$ can be discretized with forward Euler using equation \ref{eq:euler} from task 2. The bias can be written in state space form as

\begin{equation}
	\dot{\bm{x}} = 
	\begin{bmatrix}
		-\frac{1}{T_1} & 0 \\
		0 & -\frac{1}{T_2}
	\end{bmatrix}
	\bm{x} +
	\begin{bmatrix}
		1 & 0 \\
		0 & 1
	\end{bmatrix}
	\bm{w}
\end{equation}

where

\begin{center}
\begin{math}
	\bm{x} =
	\begin{bmatrix}
		b_1 \\ b_2
	\end{bmatrix}
	, \hspace{5pt} \bm{w} =
	\begin{bmatrix}
		w_1 \\ w_2
	\end{bmatrix}
	.
\end{math}
\end{center}

The resulting discretized system is:

\begin{equation}
	\bm{x}(t_{k+1}) =
	\begin{bmatrix}
		1 - \frac{h}{T_1} & 0 \\
		0 & 1 - \frac{h}{T_2}
	\end{bmatrix}
	\bm{x}(t_k) +
	\begin{bmatrix}
		h & 0 \\
		0 & h
	\end{bmatrix}
	\bm{w}(t_k).
\end{equation}

\begin{figure}[!ht]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.25\textwidth, keepaspectratio=true]{../src/disc_bias.eps}}
    \caption{Bias modelled as a Gauss-Markov process.}
    \label{fig:disc_bias}
\end{figure}

\begin{figure}[!ht]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.25\textwidth, keepaspectratio=true]{../src/accel_task3.eps}}
    \caption{Measured acceleration.}
    \label{fig:accel_task3}
\end{figure}

\begin{figure}[!ht]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.25\textwidth, keepaspectratio=true]{../src/angular_vel_task3.eps}}
    \caption{The measure angular velocity.}
    \label{fig:angular_vel_task3}
\end{figure}

\begin{figure}[!ht]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.25\textwidth, keepaspectratio=true]{../src/position_task3.eps}}
    \caption{The measured position.}
    \label{fig:pos_task3}
\end{figure}

\begin{figure}[!ht]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.25\textwidth, keepaspectratio=true]{../src/orientation_task3.eps}}
    \caption{Measured orientation.}
    \label{fig:orientation_task3}
\end{figure}


\section*{Task 4}
The Kalman filter consists of several equations, which can be found in table 4.1 in \cite{heftet}.

The design matrices of the Kalman filter, $\bm{Q}$ and $\bm{R}$ are chosen based on knowledge of the variance in the system, and must satisfy the condition

\begin{equation}
	\bm{Q}_d(k) = \bm{Q}^T_d(k) > 0, \hspace{5pt} \bm{R}_d(k) = \bm{R}_d(k) > 0.
\end{equation}

The initial condistions of the filter are chose as

\begin{subequations}
\begin{equation}
	\bar{\bm{x}}(0) = \bm{x}_0
\end{equation}
\begin{equation}
	\bar{\bm{P}}(0) = E[(\bm{x}(0)-\hat{\bm{x}}(0))(\bm{x}(0)-\hat{\bm{x}}(0))^T] = \bm{P}_0.
\end{equation}
\end{subequations}
	
The Kalman gain matrix is calculated by

\begin{equation}
	\bm{K}(k) = \bar{\bm{P}}(k)\bm{H}^T(k)[\bm{H}(k)\bar{\bm{P}}(k)\bm{H}^T(k) + \bm{R}_d(k)]^{-1}
\end{equation}

and the state estimation performed at every timestep is defined as

\begin{equation}
	\hat{\bm{x}}(k) = \bar{\bm{x}}(k) + \bm{K}(k)[\bm{y}(k)-\bm{H}(k)\bar{\bm{x}}(k)].
\end{equation}
	
The error covariance update is defined as

\begin{equation}
	\hat{\bm{P}}(k) = [\bm{I}-\bm{K}(k)\bm{H}(k)]\bar{\bm{P}}(k)[\bm{I}-\bm{K}(k)\bm{H}(k)]^T+\bm{K}(k)\bm{R}_d(k)\bm{K}^T(k).
\end{equation}
	
The propagation of the system is updated in both the state estimation and the error covariance

\begin{subequations}
\begin{equation}
	\bar{\bm{x}}(k+1) = \bm{\Phi}(k)+\hat{\bm{x}}(k)+\Updelta(k)\bm{u}(k)
\end{equation}
\begin{equation}
	\bar{\bm{P}}(k+1) = \bm{\Phi}(k)\hat{\bm{P}}(k)\bm{\Phi}^T(k)+\bm{\Gamma}(k)\bm{Q}_d(k)\bm{\Gamma}^T(k).
\end{equation}
\end{subequations}

	

\newpage
\addcontentsline{toc}{chapter}{References}
\begin{thebibliography}{25}

	\bibitem{heftet}
	Vik, Bj√∏rnar (2014)
	\emph{"Integrated Satellite and Inertial Navigation Systems"},
	Norwegian University of Science and Technology, Department of Engineering Cybernetics, Trondheim
	
	\bibitem{wikiWhite}
	Wikipedia,
	\emph{https://en.wikipedia.org/wiki/White\_noise},
	accessed 05.11.2016
	
\end{thebibliography}

\end{document}